{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy import spatial\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from functions import calcBandwidth\n",
    "from functions import calcFD\n",
    "from functions import calcBandPowers\n",
    "from functions import getIMFstats\n",
    "from functions import getStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import features and labels\n",
    "features = np.load(\"../data/other/features_raw.npy\")\n",
    "labels = np.load(\"../data/other/labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape features to get the channels before the samples\n",
    "features_eeg = features.reshape(2717, 20, -1)\n",
    "features_eeg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for deducting right hemisphere channels from the left hemisphere channels.\n",
    "def deduct_features_after_extraction(features):\n",
    "    left = [0,2,3,4,5,6,7,8,9]\n",
    "    right = [10,12,13,14,15,16,17,18,19]\n",
    "    neutral = [1,11]\n",
    "    for nF, feature in enumerate(features):\n",
    "        multiplyer = int(feature.shape[1] / 20)\n",
    "        for nR, row in enumerate(feature):\n",
    "            for c in range(0,len(left)):\n",
    "                deduction = row[(left[c]*multiplyer):((left[c]+1)*multiplyer)]-row[(right[c]*multiplyer):((right[c]+1)*multiplyer)]\n",
    "                if c == 0:\n",
    "                    temp_array = deduction\n",
    "                else:\n",
    "                    temp_array = np.hstack((temp_array, deduction))\n",
    "            temp_array = np.hstack((temp_array,row[(neutral[0]*multiplyer):((neutral[0]+1)*multiplyer)]))\n",
    "            temp_array = np.hstack((temp_array,row[(neutral[1]*multiplyer):((neutral[1]+1)*multiplyer)]))\n",
    "            if nR == 0:\n",
    "                temp_feature = temp_array\n",
    "            else:\n",
    "                temp_feature = np.vstack((temp_feature, temp_array))\n",
    "        if nF == 0:\n",
    "            result = temp_feature\n",
    "        else:\n",
    "            result = np.vstack((result, temp_feature))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running functions to create the features. Functions are specified in functions.py\n",
    "features_eeg_FD = calcFD(features_eeg, 50)\n",
    "features_eeg_bp = calcBandPowers(features_eeg)\n",
    "features_eeg_stat = getStatistics(features_eeg)\n",
    "features_eeg_hht = getIMFstats(features_eeg)\n",
    "\n",
    "# Apply the deduction function\n",
    "deductFD = deduct_features_after_extraction(features_eeg_FD.reshape(1,2717,20))\n",
    "deductStat = deduct_features_after_extraction(features_eeg_stat.reshape(1,2717,-1))\n",
    "deductBP = deduct_features_after_extraction(features_eeg_bp.reshape(1,2717,-1))\n",
    "deductHHT = deduct_features_after_extraction(features_eeg_hht.reshape(1,2717,-1))\n",
    "\n",
    "# Combine feature setup 1\n",
    "features_result = np.hstack((deductFD, deductStat))\n",
    "features_result = np.hstack((features_result, deductBP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split setup 1 features into train/test\n",
    "X_train, X_test, A_train, A_test = train_test_split(\n",
    "    features_result, labels[0], test_size=0.3, random_state=42)\n",
    "X_train, X_test, V_train, V_test = train_test_split(\n",
    "    features_result, labels[1], test_size=0.3, random_state=42)\n",
    "\n",
    "# Split setup 2 features into train/test\n",
    "X_train2, X_test2, A_train2, A_test2 = train_test_split(\n",
    "    deductHHT, labels[0], test_size=0.3, random_state=42)\n",
    "X_train2, X_test2, V_train2, V_test2 = train_test_split(\n",
    "    deductHHT, labels[1], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running all models for setup 1\n",
    "LR_Arousal_1 = LinearRegression()\n",
    "LR_Arousal_1.fit(X_train, A_train)\n",
    "LR_Arousal_1_results = LR_Arousal_1.predict(X_test)\n",
    "print(\"Arousal, MAE:\", mean_absolute_error(A_test, LR_Arousal_1_results))\n",
    "print(\"Arousal, bandwidth:\", calcBandwidth(A_test, LR_Arousal_1_results))\n",
    "\n",
    "KNN_Arousal_1 = KNeighborsRegressor(20)\n",
    "KNN_Arousal_1.fit(X_train, A_train)\n",
    "KNN_Arousal_1_results = KNN_Arousal_1.predict(X_test)\n",
    "print(\"Arousal, MAE:\", mean_absolute_error(A_test, KNN_Arousal_1_results))\n",
    "print(\"Arousal, bandwidth:\", calcBandwidth(A_test, KNN_Arousal_1_results))\n",
    "\n",
    "SVR_Arousal_1 = SVR(C = 0.6, epsilon = 0.05)\n",
    "SVR_Arousal_1.fit(X_train, A_train)\n",
    "SVR_Arousal_1_results = SVR_Arousal_1.predict(X_test)\n",
    "print(\"Arousal, MAE:\", mean_absolute_error(A_test, SVR_Arousal_1_results))\n",
    "print(\"Arousal, bandwidth:\", calcBandwidth(A_test, SVR_Arousal_1_results))\n",
    "\n",
    "LR_Valence_1 = LinearRegression()\n",
    "LR_Valence_1.fit(X_train, V_train)\n",
    "LR_Valence_1_results = LR_Valence_1.predict(X_test)\n",
    "print(\"\\nValence, MAE:\", mean_absolute_error(V_test, LR_Valence_1_results))\n",
    "print(\"Valence, bandwidth:\", calcBandwidth(V_test, LR_Valence_1_results))\n",
    "\n",
    "KNN_Valence_1 = KNeighborsRegressor(25)\n",
    "KNN_Valence_1.fit(X_train, V_train)\n",
    "KNN_Valence_1_results = KNN_Valence_1.predict(X_test)\n",
    "print(\"Valence, MAE:\", mean_absolute_error(V_test, KNN_Valence_1_results))\n",
    "print(\"Valence, bandwidth:\", calcBandwidth(V_test, KNN_Valence_1_results))\n",
    "\n",
    "SVR_Valence_1 = SVR(C = 3, epsilon = 0.1)\n",
    "SVR_Valence_1.fit(X_train, V_train)\n",
    "SVR_Valence_1_results = SVR_Valence_1.predict(X_test)\n",
    "print(\"Valence, MAE:\", mean_absolute_error(V_test, SVR_Valence_1_results))\n",
    "print(\"Valence, bandwidth:\", calcBandwidth(V_test, SVR_Valence_1_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running all models for setup 2\n",
    "LR_Arousal_2 = LinearRegression()\n",
    "LR_Arousal_2.fit(X_train2, A_train2)\n",
    "LR_Arousal_2_results = LR_Arousal_2.predict(X_test2)\n",
    "print(\"Arousal, MAE:\", mean_absolute_error(A_test2, LR_Arousal_2_results))\n",
    "print(\"Arousal, bandwidth:\", calcBandwidth(A_test2, LR_Arousal_2_results))\n",
    "\n",
    "KNN_Arousal_2 = KNeighborsRegressor(17, weights = \"distance\")\n",
    "KNN_Arousal_2.fit(X_train2, A_train2)\n",
    "KNN_Arousal_2_results = KNN_Arousal_2.predict(X_test2)\n",
    "print(\"Arousal, MAE:\", mean_absolute_error(A_test2, KNN_Arousal_2_results))\n",
    "print(\"Arousal, bandwidth:\", calcBandwidth(A_test2, KNN_Arousal_2_results))\n",
    "\n",
    "SVR_Arousal_2 = SVR(C = 0.6, epsilon = 0.1)\n",
    "SVR_Arousal_2.fit(X_train2, A_train2)\n",
    "SVR_Arousal_2_results = SVR_Arousal_2.predict(X_test2)\n",
    "print(\"Arousal, MAE:\", mean_absolute_error(A_test2, SVR_Arousal_2_results))\n",
    "print(\"Arousal, bandwidth:\", calcBandwidth(A_test2, SVR_Arousal_2_results))\n",
    "\n",
    "LR_Valence_2 = LinearRegression()\n",
    "LR_Valence_2.fit(X_train2, V_train2)\n",
    "LR_Valence_2_results = LR_Valence_2.predict(X_test2)\n",
    "print(\"\\nValence, MAE:\", mean_absolute_error(V_test2, LR_Valence_2_results))\n",
    "print(\"Valence, bandwidth:\", calcBandwidth(V_test2, LR_Valence_2_results))\n",
    "\n",
    "KNN_Valence_2 = KNeighborsRegressor(17, p = 2)\n",
    "KNN_Valence_2.fit(X_train2, V_train2)\n",
    "KNN_Valence_2_results = KNN_Valence_2.predict(X_test2)\n",
    "print(\"Valence, MAE:\", mean_absolute_error(V_test2, KNN_Valence_2_results))\n",
    "print(\"Valence, bandwidth:\", calcBandwidth(V_test2, KNN_Valence_2_results))\n",
    "\n",
    "SVR_Valence_2 = SVR(C = 0.8, epsilon = 0.1)\n",
    "SVR_Valence_2.fit(X_train2, V_train2)\n",
    "SVR_Valence_2_results = SVR_Valence_2.predict(X_test2)\n",
    "print(\"\\nValence, MAE:\", mean_absolute_error(V_test2, SVR_Valence_2_results))\n",
    "print(\"Valence, bandwidth:\", calcBandwidth(V_test2, SVR_Valence_2_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating the bins inside the predictions\n",
    "def calcBins(predictions, true, element):\n",
    "    dimensions = [[1,7], [2,8]]\n",
    "    result = []\n",
    "    tres = 0.1 * (np.max(true) - np.min(true))\n",
    "    \n",
    "    for n in range(dimensions[element][0], dimensions[element][1]):\n",
    "        temp_n = 0\n",
    "        sum1 = 0\n",
    "        for p,t in zip(predictions, true):\n",
    "            if (t >= n) & (t < n+1):\n",
    "                var = spatial.distance.euclidean(p,t)\n",
    "                if var < tres:\n",
    "                    temp_n += 1\n",
    "                sum1 += 1\n",
    "        if temp_n != 0:\n",
    "            result += [temp_n/sum1*100]\n",
    "        else:\n",
    "            result += [0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applied\n",
    "t1 = calcBins(LR_Arousal_1_results, A_test,0)\n",
    "t2= calcBins(LR_Arousal_2_results, A_test2, 0)\n",
    "t3 = calcBins(KNN_Arousal_1_results, A_test, 0)\n",
    "t4 = calcBins(KNN_Arousal_2_results, A_test2, 0)\n",
    "t5 = calcBins(SVR_Arousal_1_results, A_test, 0)\n",
    "t6 = calcBins(SVR_Arousal_2_results, A_test2, 0)\n",
    "\n",
    "t10 = calcBins(LR_Valence_1_results, V_test,1)\n",
    "t11 = calcBins(LR_Valence_2_results, V_test2, 1)\n",
    "t12 = calcBins(KNN_Valence_1_results, V_test, 1)\n",
    "t13 = calcBins(KNN_Valence_2_results, V_test2, 1)\n",
    "t14 = calcBins(SVR_Valence_1_results, V_test, 1)\n",
    "t15 = calcBins(SVR_Valence_2_results, V_test2, 1)\n",
    "\n",
    "arousalBins = [t1, t2, t3, t4, t5, t6]\n",
    "valenceBins = [t10, t11, t12, t13, t14, t15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction heatmap arousal\n",
    "plt.figure(dpi = 250)\n",
    "ax = sns.heatmap(np.array(test7), linewidth=0.9)\n",
    "plt.xlabel(\"True arousal\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.xticks(np.arange(7),[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\"])\n",
    "plt.yticks(np.arange(7), [\"LR-1\", \"LR-2\", \"KNNR-1\", \"KNNR-2\", \"SVR-1\", \"SVR-2\"], rotation = 20)\n",
    "plt.savefig(\"../Visuals/heatmap_predictions_arousal.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Prediction heatmap valence\n",
    "plt.figure(dpi = 250)\n",
    "ax = sns.heatmap(np.array(test8), linewidth=0.9)\n",
    "plt.xlabel(\"True valence\")\n",
    "plt.ylabel(\"Model\")\n",
    "plt.xticks(np.arange(7),[\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\"])\n",
    "plt.yticks(np.arange(7), [\"LR-1\", \"LR-2\", \"KNNR-1\", \"KNNR-2\", \"SVR-1\", \"SVR-2\"], rotation = 20)\n",
    "plt.savefig(\"../Visuals/heatmap_predictions_valence.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent t-test\n",
    "stats.ttest_ind(SVR_Arousal_1_results, KNN_Arousal_2_results)\n",
    "stats.ttest_ind(KNN_Valence_1_results, KNN_Valence_2_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's r correlations between arousal and setup 1\n",
    "correlations = []\n",
    "for i in range(features_result.shape[1]):\n",
    "    correlations += [scipy.stats.pearsonr(features_result[:,i], labels[0])[0]]\n",
    "    \n",
    "# Pearson's r correlations between arousal and setup 2\n",
    "correlations_hht = []\n",
    "for i in range(deductHHT.shape[1]):\n",
    "    correlations_hht += [scipy.stats.pearsonr(deductHHT[:,i], labels[0])[0]]\n",
    "\n",
    "# Pearson's r correlations between valence and setup 1\n",
    "correlations2 = []\n",
    "for i in range(features_result.shape[1]):\n",
    "    correlations2 += [scipy.stats.pearsonr(features_result[:,i], labels[1])[0]]\n",
    "\n",
    "# Pearson's r correlations between valence and setup 2\n",
    "correlations_hht2 = []\n",
    "for i in range(deductHHT.shape[1]):\n",
    "    correlations_hht2 += [scipy.stats.pearsonr(deductHHT[:,i], labels[1])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot setup 1\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "plt.figure(dpi = 150)\n",
    "sns.distplot(correlations, label = \"Arousal\")\n",
    "sns.distplot(correlations2, label = \"Valence\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Pearsons' r correlation\")\n",
    "plt.ylabel(\"Number of features correlated\")\n",
    "plt.savefig(\"../Visuals/correlations_setup_1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot setup 2\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "plt.figure(dpi = 150)\n",
    "sns.distplot(correlations_hht, label = \"Arousal\")\n",
    "sns.distplot(correlations_hht2, label = \"Valence\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Pearsons' r correlation\")\n",
    "plt.ylabel(\"Number of features correlated\")\n",
    "plt.savefig(\"../Visuals/correlations_setup_2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction matrix of the two-dimensional model arousal-valence\n",
    "plt.figure(dpi = 250)\n",
    "sns.scatterplot(x = A_test, y = V_test, marker = \"+\", label=\"Label\")\n",
    "sns.scatterplot(x = KNN_Arousal_2_results, y = KNN_Valence_2_results, label = \"Prediction\")\n",
    "plt.xlim(1,7)\n",
    "plt.ylim(3,8)\n",
    "plt.xlabel(\"Arousal\")\n",
    "plt.ylabel(\"Valence\")\n",
    "plt.legend()\n",
    "plt.savefig(\"../Visuals/prediction_matrix.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density estimations for labels\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "plt.figure(dpi = 150)\n",
    "sns.distplot(labels[0], label = \"Arousal\")\n",
    "sns.distplot(labels[1], label = \"Valence\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Value for emotion\")\n",
    "plt.ylabel(\"Density estimation\")\n",
    "plt.savefig(\"../Visuals/distribution_arousal_valence.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustment of a function in pyhht package, so that the plot becomes better\n",
    "def plot_imfs2(signal, imfs, time_samples=None, fignum=None, show=True):\n",
    "    \"\"\"\n",
    "    Plot the signal, IMFs and residue.\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : array-like, shape (n_samples,)\n",
    "        The input signal.\n",
    "    imfs : array-like, shape (n_imfs, n_samples)\n",
    "        Matrix of IMFs as generated with the `EMD.decompose` method.\n",
    "    time_samples : array-like, shape (n_samples), optional\n",
    "        Time instants of the signal samples.\n",
    "        (defaults to `np.arange(1, len(signal))`)\n",
    "    fignum : int, optional\n",
    "        Matplotlib figure number (by default a new figure is created)\n",
    "    show : bool, optional\n",
    "        Whether to display the plot. Defaults to True, set to False if further\n",
    "        plotting needs to be done.\n",
    "    Returns\n",
    "    -------\n",
    "    `matplotlib.figure.Figure`\n",
    "        The figure (new or existing) in which the decomposition is plotted.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from pyhht.visualization import plot_imfs\n",
    "    >>> import numpy as np\n",
    "    >>> from pyhht import EMD\n",
    "    >>> t = np.linspace(0, 1, 1000)\n",
    "    >>> modes = np.sin(2 * np.pi * 5 * t) + np.sin(2 * np.pi * 10 * t)\n",
    "    >>> x = modes + t\n",
    "    >>> decomposer = EMD(x)\n",
    "    >>> imfs = decomposer.decompose()\n",
    "    >>> plot_imfs(x, imfs, t) #doctest: +SKIP\n",
    "    .. plot:: ../../docs/examples/simple_emd.py\n",
    "    \"\"\"\n",
    "    is_bivariate = np.any(np.iscomplex(signal))\n",
    "    if time_samples is None:\n",
    "        time_samples = np.arange(signal.shape[0])\n",
    "\n",
    "    n_imfs = imfs.shape[0]\n",
    "\n",
    "    fig = plt.figure(num=fignum, dpi = 250)\n",
    "    axis_extent = max(np.max(np.abs(imfs[:-1, :]), axis=0))\n",
    "\n",
    "    # Plot original signal\n",
    "    ax = plt.subplot(n_imfs + 1, 1, 1)\n",
    "    if is_bivariate:\n",
    "        ax.plot(time_samples, np.real(signal), 'b')\n",
    "        ax.plot(time_samples, np.imag(signal), 'k--')\n",
    "    else:\n",
    "        ax.plot(time_samples, signal)\n",
    "    ax.axis([time_samples[0], time_samples[-1], signal.min(), signal.max()])\n",
    "    ax.tick_params(which='both', left=False, bottom=False, labelleft=False,\n",
    "                   labelbottom=False)\n",
    "    ax.grid(False)\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_title('Empirical Mode Decomposition')\n",
    "\n",
    "    # Plot the IMFs\n",
    "    for i in range(n_imfs - 1):\n",
    "        ax = plt.subplot(n_imfs + 1, 1, i + 2)\n",
    "        if is_bivariate:\n",
    "            ax.plot(time_samples, np.real(imfs[i]), 'b')\n",
    "            ax.plot(time_samples, np.imag(imfs[i]), 'k--')\n",
    "        else:\n",
    "            ax.plot(time_samples, imfs[i])\n",
    "        ax.axis([time_samples[0], time_samples[-1], -axis_extent, axis_extent])\n",
    "        ax.tick_params(which='both', left=False, bottom=False, labelleft=False,\n",
    "                       labelbottom=False)\n",
    "        ax.grid(False)\n",
    "        ax.set_ylabel('imf' + str(i + 1))\n",
    "\n",
    "    # Plot the residue\n",
    "    ax = plt.subplot(n_imfs + 1, 1, n_imfs + 1)\n",
    "    if is_bivariate:\n",
    "        ax.plot(time_samples, np.real(imfs[-1]), 'r')\n",
    "        ax.plot(time_samples, np.imag(imfs[-1]), 'r--')\n",
    "    else:\n",
    "        ax.plot(time_samples, imfs[-1])\n",
    "    ax.axis('tight')\n",
    "    ax.tick_params(which='both', left=False, bottom=False, labelleft=False,\n",
    "                   labelbottom=False)\n",
    "    ax.grid(False)\n",
    "    ax.set_ylabel('res.')\n",
    "\n",
    "    if show:  # pragma: no cover\n",
    "        plt.savefig(\"../Visuals/IMF_example.png\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot IMFs\n",
    "plot_imfs2(x, imfs, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot signal example\n",
    "plt.figure(dpi = 150)\n",
    "\n",
    "plt.plot(np.linspace(0,2, 1332), features.reshape(2717, 20, -1)[0][0])\n",
    "plt.xlabel(\"Seconds\")\n",
    "plt.ylabel(\"Processed signal\")\n",
    "plt.savefig(\"../Visuals/raw_signal_example.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
